# 효율적인 파인튜닝 (PEFT)

## 1. PEFT (Parameter-Efficient Fine-Tuning)

### (1) 개념
- **PEFT**는 모든 파라미터를 수정하지 않고, **일부 파라미터만 조정하여** 모델을 효율적으로 파인튜닝하는 방법이다.
- 기존의 **Full Fine-Tuning**은 모델 전체를 재학습하지만, PEFT는 **메모리·연산량을 줄이면서도 성능 저하를 최소화**한다.
- 대표적인 접근 방식은 **LoRA (Low-Rank Adaptation)**.

### (2) 방식 비교

| 구분 | Full Fine-Tuning | LoRA (PEFT) |
|------|------------------|--------------|
| 조정 범위 | 모든 파라미터 수정 | 일부 저차원 행렬(A, B)만 추가·학습 |
| 메모리 사용량 | 매우 큼 | 작음 |
| 연산 효율 | 낮음 | 높음 |
| 장점 | 높은 적응력 | 빠른 학습, 경량 모델 생성 |
| 적용 예시 | 대형 언어 모델(LLM) | 경량 모델, 도메인 특화 파인튜닝 |


## 2. 모델 경량화의 필요성

### (1) 왜 필요한가?
- **추론/서비스 영역에서 선택이 아닌 필수**
- 일반적으로 경량화 시 성능이 일부 저하되지만,  
  모델 크기·속도·전력 효율성 등 현실적인 이점이 크다.
- GPU 자원 및 메모리 제약이 있는 환경에서는 필수적이다.

### (2) 주요 경량화 기법

| GPU 친화적 | 비GPU 친화적 |
|-------------|--------------|
| LoRA / QLoRA | Aggressive Quantization |
| Knowledge Distillation | Mixed-Precision Quantization |
| Structured Pruning | Unstructured Pruning |


## 3. 양자화 (Quantization)

### (1) 개념
- **연산 및 메모리 부하를 줄이는 가장 직접적인 방법**
- 실수(FP32)로 표현된 가중치/입력을 **정수(INT8, INT4 등)** 로 축소 변환
- 메모리 절감, 추론 속도 향상, 연산 효율성 확보

### (2) 주요 요소
- **Clipping Range**에 따른 `scaling factor` 조정이 핵심
- 모델마다 최적의 quantization 옵션이 다르며,  
  일부는 하드웨어/가속기 지원이 필요

### (3) QAT vs PTQ

| 구분 | PTQ (Post-Training Quantization) | QAT (Quantization-Aware Training) |
|------|----------------------------------|-----------------------------------|
| 시점 | 학습 후 | 학습 중 |
| 정확도 | 약간 감소 | 유지 혹은 향상 |
| 필요 데이터 | 없음 | 학습 데이터 필요 |
| 복잡도 | 낮음 | 높음 |

### (4) 적용 형태
- **Weight-Only Quantization:** 모델 크기 중심 (FP16 → INT8 등)
- **Activation Quantization:** 연산 효율 중심
- **De-quantization**은 정확도 유지용으로 병행

### (5) Symmetric vs Asymmetric
| 구분 | Symmetric | Asymmetric |
|------|------------|-------------|
| 범위 중심 | 0 기준 대칭 | 비대칭 |
| 정확도 | 높음 | 범용성 높음 |
| 하드웨어 지원 | GPU에 유리 | 범용 CPU 환경에 유리 |


## 4. 가지치기 (Pruning)

### (1) 개념
- **불필요한 weight(기여도 낮은 값)** 제거 → 모델 크기 감소
- 저장 공간 및 연산량 절약
- Quantization 이후에도 추가 경량화 가능

### (2) 고려 사항
- 남은 weight 위치 저장을 위한 **indexing data** 필요
- GPU 환경에서는 속도 이득이 크지 않을 수도 있음 (전용 가속기 필요)

### (3) Fine-Tuning 및 GPU 호환성
- **Fine-tuning** 시 CNN 모델은 약 80% 이상 pruning 가능 (정확도 손실 1~2%)
- LLM 모델은 약 50% 수준 가능
- GPU와 pruning 패턴 간 비호환성 존재 → NPU 등 sparsity-aware 설계 필요

## 5. 지식 증류 (Knowledge Distillation)

### (1) 개념
- **작은 모델(Student)** 을 **큰 모델(Teacher)** 의 지식을 통해 학습시키는 방법
- Teacher의 출력(soft label)을 활용하여 Student가 비슷한 판단을 하도록 학습
- 목표: **작지만 성능이 뛰어난 모델 생성**

### (2) 원리
1. Teacher 모델이 먼저 문제를 해결 (정답 확률 분포 제공)
2. Student 모델이 이를 모방하며 학습
3. 성능은 Teacher에 근접하지만 크기는 훨씬 작음

### (3) LLM Distillation
- 거대한 LLM을 Teacher로 삼아 **작은 LLM에 지식 전이**
- 성능이 일반 학습보다 뛰어나지만, **데이터 양이 매우 크면 여전히 학습 비용이 높음**
- 예시: ChatGPT 응답 데이터를 이용해 “모방형 Student LLM” 학습 (fine-tuning)


## 6. 전체 요약

| 구분 | 목적 | 핵심 아이디어 | 장점 |
|------|------|----------------|------|
| **LoRA / QLoRA (PEFT)** | 효율적 파인튜닝 | 일부 저차원 파라미터만 학습 | 적은 자원, 빠른 학습 |
| **Quantization** | 메모리 절약 / 속도 향상 | 실수를 정수로 변환 | 연산량 절감 |
| **Pruning** | 불필요한 Weight 제거 | 기여도 낮은 Weight 제거 | 모델 크기 감소 |
| **Distillation** | 작은 모델로 지식 전이 | Teacher → Student 학습 | 경량 모델 생성 |

---

✅ **핵심 정리**
- PEFT는 “모든 파라미터를 다 건드리지 않는다”는 철학을 기반으로 한다.  
- **LoRA → Quantization → Pruning → Distillation** 은  
  모델 효율성을 높이는 핵심 흐름이며,  
  **경량화 + 성능 유지** 라는 AI 모델 실무의 핵심 과제 해결책이다.

---

# LoRA / QLoRA (파인튜닝 심화)

## 1. 파인튜닝(Fine-Tuning)의 개념

### (1) 모델 경량화 관점
- **원본 모델의 크기를 줄이거나 성능을 복원**하기 위해 수행하는 과정  
- 일부 또는 전체 데이터를 다시 학습시켜 모델의 성능(accuracy)을 유지 또는 개선  
- 예: 비손실 양자화 이후 정확도 복원을 위한 QAT(Qualization-Aware Training)

### (2) 모델 서비스 관점 (특히 LLM)
- 일반적인 능력을 가진 **원본 모델(Base Model)** 을  
  특정 **도메인 또는 목적(Task)** 에 맞게 조정하는 과정  
- 완전히 새로운 모델을 만드는 것이 아니라,  
  기존 모델을 **“조정·특화”** 하는 방식으로 활용됨


## 2. 다양한 파인튜닝 접근 방식

### (1) In-Context Learning
- **모델을 직접 수정하지 않고**, 프롬프트 설계를 통해 원하는 행동을 유도하는 방법  
- 기존 파라미터는 그대로 두고, 입력 문맥(Context) 내에서 학습한 것처럼 동작

### (2) Full Fine-Tuning
- 특정 도메인 데이터를 사용해 **모든 weight를 다시 학습**  
- **장점:** 정확도 향상, 도메인 특화에 강함  
- **단점:** 계산량 및 메모리 부담이 매우 큼, 기존 지식 손실 가능


## 3. 파라미터 효율적 파인튜닝 (PEFT)

PEFT는 **원본 모델의 weight를 전부 수정하지 않고**,  
특정 부분에만 학습 가능한 파라미터를 추가하여 효율적인 튜닝을 수행한다.  
LLM을 도메인 특화시키는 데 필요한 연산량을 **크게 줄이는 핵심 기법**이다.


## 4. 주요 PEFT 기법 비교

### (1) Adapter Layer
- 기존 네트워크에 **새로운 layer를 추가**하여 특화된 데이터만 학습  
- 예: 입력과 출력 사이에 작은 MLP 형태의 Adapter 추가  
- **장점:** 기존 가중치를 고정하면서 새로운 표현력을 얻을 수 있음  
- **단점:** Adapter가 여러 개 쌓이면 메모리·연산량이 다시 증가

### (2) Prompt Tuning
- 입력 임베딩 앞·뒤에 **가짜 토큰(pseudo-token)** 을 삽입  
- 아주 적은 수의 파라미터만 학습해 입력 동작을 조정  
- **장점:** 가볍고 배포 쉬움  
- **단점:** 표현력 제한 → 복잡한 도메인에선 성능 저하


## 5. Low-Rank Adaptation (LoRA)

### (1) 개념
- 기존 weight matrix에 **저차원 행렬(Low-Rank)** 을 추가하여 파인튜닝  
- 기존 가중치는 고정하고, 새로운 저차원 행렬만 학습  

### (2) 수식 구조
- 기존 weight W 대신 `W + ΔW` 사용  
- ΔW는 `A × B` 형태의 저차원 행렬 (rank r << d)

### (3) 특징
- **메모리 절약:** 추가 파라미터 수가 매우 적음  
- **효율성:** Adapter layer보다 훨씬 가볍고 빠름  
- **적용성:** LLM, Vision Transformer 등 대형 모델에 광범위하게 활용  

| 구분 | Full Fine-Tuning | LoRA |
|------|------------------|------|
| 학습 파라미터 수 | 100% | 약 0.1~1% |
| 기존 weight 수정 | 있음 | 없음 |
| 메모리 사용량 | 높음 | 낮음 |
| 대표 적용 분야 | 전체 도메인 학습 | 도메인 특화, 추가 학습 |


## 6. Quantized LoRA (QLoRA)

### (1) 개념
- **양자화(Quantization)** 와 **LoRA** 를 결합한 경량화 파인튜닝 기법  
- 대형 모델을 **저비트(예: 4-bit)** 로 압축하면서 LoRA로 효율적 학습 수행  
- Quantization으로 연산량을 줄이고, LoRA로 성능 보완

### (2) 구조
1. 원본 모델을 4-bit 정밀도로 양자화 (예: NF4 포맷)
2. LoRA 모듈(저차원 행렬)을 추가하여 미세 조정  
3. 원본 가중치는 고정, LoRA 가중치만 학습  

### (3) 장점
- **저비용 학습:** GPU 메모리 사용량 대폭 감소  
- **성능 유지:** LoRA로 양자화로 인한 성능 손실 보완  
- **적용 용이:** 기존 LoRA 코드와 거의 동일하게 활용 가능  

### (4) 성능 예시
| Model | Bits | GLUE (Acc) | SuperNatural | RougeL |
|--------|------|-------------|---------------|---------|
| LoRA BF16 | 16-bit | 88.6 | 40.1 | 54.3 |
| **QLoRA Int8** | 8-bit | **88.6** | **40.1** | **54.3** |
| **QLoRA NF4 + DQ** | 4-bit | **88.4** | **40.2** | **54.5** |

→ **저비트 환경에서도 LoRA 성능 거의 동일하게 유지**

## 7. 전체 비교 요약

| 기법 | 주요 개념 | 학습 파라미터 | 장점 | 단점 |
|------|------------|----------------|------|------|
| **Full FT** | 모든 weight 학습 | 100% | 정확도 높음 | 계산량 큼 |
| **Adapter** | 새 layer 추가 | 중간 | 표현력 향상 | 오버헤드 있음 |
| **Prompt Tuning** | 가짜 토큰 삽입 | 매우 적음 | 빠르고 경량 | 표현력 제한 |
| **LoRA** | 저차원 행렬 추가 | 극소 | 효율적, 성능 우수 | 세밀 조정 필요 |
| **QLoRA** | 양자화 + LoRA 결합 | 극소 | 자원 절감 + 성능 유지 | 정밀도 손실 가능 |

---

✅ **핵심 정리**
- **LoRA**는 “적은 파라미터로도 높은 표현력”을 얻는 방법이다.  
- **QLoRA**는 “4-bit 환경에서도 대형 모델을 학습할 수 있게 한 혁신적 경량화 기법”이다.  
- 이 두 방법은 **PEFT(효율적 파인튜닝)** 의 핵심 축으로,  
  **대형 모델(LLM)을 효율적으로 재학습시키는 현대 AI의 필수 기술**로 자리 잡고 있다.
