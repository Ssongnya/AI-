# 선형 회귀

## 1. 선형 회귀 (Linear Regression)

### 🧩 정의
- 입력 변수(X)와 출력 변수(Y) 사이의 관계를 **직선 형태로 근사하여 예측**하는 통계적 방법  
- 지도학습(Supervised Learning)의 **가장 기초적인 접근법** 중 하나  
- 단순하지만 **개념적으로도, 실무적으로도 매우 유용**함  

### 📊 특징
- 관계 수식: `Y = aX + b`  
  - a: 기울기(slope), b: 절편(intercept)
- 데이터를 가장 잘 설명하는 직선을 찾는 것이 핵심
- 예측, 추세 파악, 변수 간 상관관계 분석에 널리 사용됨

### 💡 예시 그래프
- TV, Radio, Newspaper 광고비와 매출 간의 관계 예시
- 각 매체 광고비가 증가할수록 매출도 증가하는 **양의 상관관계** 존재
- 산점도 위의 파란색 선은 모델이 찾은 추세선(예측 방향)


## 1-2. 광고 데이터 예시

### 🎯 선형회귀를 통해 대답할 수 있는 질문
- 광고비와 매출 사이에 관계가 있는가?  
- 그 관계의 강도는 어느 정도인가?  
- 어떤 매체가 매출에 더 큰 영향을 미치는가?  
- 미래 매출을 얼마나 정확히 예측할 수 있는가?  
- 매체 간 상호작용(시너지 효과)이 존재하는가?  

### 📈 예시 그래프
- TV 광고비와 매출, Radio 광고비와 매출 간의 관계를 시각화  
- 그래프의 기울기가 **양수(+)** → 광고비 증가 시 매출 증가 경향  


> 💬 **핵심 요약**
> - 선형회귀는 “입력 → 출력” 관계를 **직선**으로 근사하는 기본적인 지도학습 모델  
> - 데이터 간의 관계를 정량적으로 이해하고 예측하는 데 유용  
> - **EDA 이후 가장 먼저 적용되는 통계적 예측 기법**

---

## 2. 단순선형회귀 (Simple Linear Regression)

### 🧩 정의
- **하나의 설명변수(X)** 와 **하나의 반응변수(Y)** 사이의 선형(직선) 관계를 찾는 방법  
- 데이터를 가장 잘 설명하는 **직선을 찾아 예측(ŷ)에 활용**  
- 지도학습 중 회귀(Regression)의 기본 형태  



## 2-1. 단일 설명변수를 이용한 선형회귀

### 📘 모형 가정
- 식: **Y = β₀ + β₁X + ε**
  - **β₀ (절편)** : X = 0일 때의 Y 값  
  - **β₁ (기울기)** : X가 1단위 증가할 때 Y가 평균적으로 얼마나 증가하는지  
  - **ε (오차항)** : 실제 관측값과 예측값의 차이  
- hat( ˆ ) 기호: 추정된 값(예: ŷ, β̂₀, β̂₁)을 의미  

### 💡 예시
- X: TV 광고비  
- Y: 제품 판매량  
- 파란 선은 데이터의 경향을 가장 잘 설명하는 회귀선(직선)



## 2-2. 최소제곱법 (Least Squares)

### 🧠 개념
- 실제 관측값과 예측값의 차이(**잔차, residual**)의 제곱합(RSS: Residual Sum of Squares)을 **최소화**하는 방법  
- 목표: 데이터를 가장 잘 설명하는 직선을 찾기 위해 **계수 β₀, β₁**을 추정  

### 📏 주요 식
- 잔차 정의: **eᵢ = yᵢ - ŷᵢ = yᵢ - (β₀ + β₁xᵢ)**
- RSS(잔차제곱합): **RSS = Σ(eᵢ²) = Σ(yᵢ - β₀ - β₁xᵢ)²**

### ⚙️ 계수 계산식 (Closed-form solution)
- 기울기(β₁):  
  **β₁ = Σ(xᵢ - x̄)(yᵢ - ȳ) / Σ(xᵢ - x̄)²**
- 절편(β₀):  
  **β₀ = ȳ - β₁x̄**

> 4차시 이후에는 경사하강법(Gradient Descent)을 통해 β₀, β₁을 추정하는 방법을 학습할 예정.


## 2-3. 단순선형회귀: 광고 데이터 예시

### 📊 사례 설명
- **목표:** TV 광고비(X)와 판매량(Y)의 선형 관계 예측  
- **방법:** 최소제곱법을 적용하여 각 데이터의 잔차제곱합이 가장 작은 직선 선택  

### 🧩 도형의 의미
- **파란 선:** 최소제곱법으로 계산된 회귀선  
- **빨간 점:** 실제 관측 데이터  
- **잔차(residual):** 실제값과 예측값의 차이(빨간 선으로 표시)  
- RSS(잔차제곱합)를 최소화할 때 β₀, β₁ 결정됨  



## 2-3. 단순선형회귀 결과 해석 (광고 데이터)

### 📈 계수 해석
| 항목 | Coefficient | 설명 |
|------|--------------|------|
| **Intercept (β̂₀)** | 7.0325 | 광고비가 0이어도 평균 판매량은 약 7.03백만 원 |
| **TV (β̂₁)** | 0.0475 | TV 광고비를 1단위(1백만 원) 늘리면 매출이 약 0.0475 × 1단위 = 4.72만 원 증가 |



### 🧮 유의성 검정
- **p-value < 0.0001 (< 0.05)** → 통계적으로 매우 유의함  
  → **TV 광고비와 매출 간 관계가 존재함**을 의미  


### 📊 모델 적합도 (R²)
| 지표 | 값 | 의미 |
|------|----|------|
| **R² = 0.612** | 판매량 변동의 약 61%를 광고비로 설명 가능 |

> 💡 R² 값이 1에 가까울수록 모델의 설명력이 높음.


> 💬 **핵심 요약**
> - 단순선형회귀는 “한 변수로 결과를 예측”하는 기본 회귀모형  
> - 최소제곱법으로 직선을 추정하며, 계수(β₀, β₁)는 데이터의 패턴을 설명  
> - 회귀 계수 해석, p-value, R²를 통해 모델의 **의미와 신뢰성**을 판단할 수 있음

---

## 3. 다중선형회귀 (Multiple Linear Regression)

### 🧩 정의
- 하나의 종속변수(Y)에 대해 **두 개 이상의 독립변수(X₁, X₂, …, Xₚ)** 를 동시에 고려하는 회귀 분석 기법  
- 단순선형회귀가 하나의 요인만 고려했다면, 다중선형회귀는 여러 요인이 복합적으로 Y에 미치는 영향을 분석  



## 3-1. 다중선형회귀란?

### 📘 개념 비교
| 구분 | 단순선형회귀 | 다중선형회귀 |
|------|---------------|---------------|
| 고려 변수 | 하나의 독립변수(X₁) | 여러 독립변수(X₁, X₂, …, Xₚ) |
| 예시 | TV 광고비 → 매출 | TV, Radio, 가격, 계절, 경쟁사 → 매출 |

### 💡 예시
- **단순선형회귀:** TV 광고비만 고려  
- **다중선형회귀:** TV + Radio 광고비를 동시에 고려  
  → 결과: 데이터가 3차원 공간에서 평면(hyperplane) 형태로 표현됨



## 3-1. 각 변수의 의미

- **Y:** 종속변수 (예측 대상, 예: 매출)
- **X₁, X₂, …, Xₚ:** 독립변수 (예: 광고비, 가격, 계절, 경쟁사 등)
- **β₀:** 절편 (X들이 모두 0일 때의 Y)
- **β₁, β₂, …, βₚ:** 각 독립변수의 회귀계수 → 변수의 영향력 크기와 방향
- **ε:** 오차항 (모델이 설명하지 못하는 부분)

📗 **수식:**  
Y = β₀ + β₁X₁ + β₂X₂ + … + βₚXₚ + ε  

> 해석: 다른 변수를 고정한 상태에서 Xᵢ가 1단위 증가할 때 Y는 평균적으로 βᵢ만큼 변화  
> 예: sales = β₀ + β₁TV + β₂radio + β₃newspaper



## 3-2. 다중선형회귀의 추정과 예측

### 📈 예측식
ŷᵢ = β̂₀ + β̂₁xᵢ₁ + β̂₂xᵢ₂ + … + β̂ₚxᵢₚ  

- 여러 변수들을 동시에 고려해 반응값(Y)을 예측  
- 목표: **잔차제곱합(RSS)** 를 최소화하는 계수(β̂₀, β̂₁, …, β̂ₚ)를 찾는 것  

### 📏 RSS 식
RSS = Σ(yᵢ - ŷᵢ)² = Σ(yᵢ - β₀ - β₁xᵢ₁ - … - βₚxᵢₚ)²  

> → 여러 입력 변수를 동시에 고려하여 데이터에 가장 잘 맞는 **평면(hyperplane)** 을 찾는 과정



## 3-3. 계수 추정 유도 (행렬 표현)

### 🧮 행렬 형태로 표현
y = Xβ + ε  
- y: 종속변수 벡터  
- X: 입력변수 행렬 (관측치 × 변수 수)  
- β: 회귀계수 벡터  
- ε: 오차항 벡터  

### 🎯 최소제곱법 목적
RSS = (y - Xβ)ᵀ(y - Xβ) → β에 대해 미분 → 0이 되는 지점(극소점)에서 최소 RSS를 찾음  

### ✅ 정규방정식 해
β̂ = (XᵀX)⁻¹Xᵀy  

> 즉, **행렬 연산을 통해 β값을 직접 계산할 수 있음**



## 3-4. 다중선형회귀 결과: 시각화

- TV, Radio 광고비를 동시에 고려한 예시  
- 데이터가 3차원 공간상에서 **평면(hyperplane)** 으로 표현  
- 붉은 점: 실제 데이터  
- 파란/초록 평면: 회귀 모델이 추정한 예측값의 평면  



## 3-5. 다중선형회귀 결과 해석 (광고 데이터)


### 🧾 유의성 검정
- **TV, Radio 광고비**의 p-value < 0.05 → 매출 증가에 유의미한 관계 존재  
- **Newspaper 광고비** p-value > 0.05 → 관계가 거의 없음  


### 📈 모델 적합도
| 지표 | 값 | 해석 |
|------|----|------|
| **R² = 0.897** | 매출 변동의 약 89.7%를 광고비로 설명 가능 → 매우 높은 설명력 |

> 💡 단순선형회귀보다 R²이 상승 → 다중 회귀가 더 정확한 예측 수행


> 💬 **핵심 요약**
> - 다중선형회귀는 여러 독립변수를 동시에 고려해 예측 정확도를 높이는 회귀모델  
> - 계수(β)는 각 변수의 영향력과 방향을 나타냄  
> - 최소제곱법과 행렬 연산을 통해 계수를 계산하며, p-value와 R²로 모델의 신뢰성을 평가  
> - 변수 선택 시 다중공선성(multicollinearity) 등의 문제도 주의해야 함

--- 

## 4. 선형회귀 주의사항


## 4-1. 검증 / 테스트셋 데이터를 활용한 성능 평가

### 📘 훈련 데이터에서의 성능
- 회귀식을 학습할 때는 **훈련 데이터만**을 사용하여 최소제곱합을 계산함  
- 학습에 사용된 데이터에서는 (X와 Y의 관계가 뚜렷할 경우) **적합(fitting)** 이 잘 되어 있을 가능성이 높음  
- 그러나 이는 모델이 학습 데이터에만 지나치게 맞춰져 있을 수 있어  
  → **테스트 데이터에서는 과대평가(overfitting)** 가능성이 높음  

### 🧩 테스트 데이터 평가의 필요성
- 모델의 일반화 성능(새로운 데이터에서의 성능)을 확인하려면  
  **훈련에 사용되지 않은 테스트 데이터로 평가해야 함**
- 변수가 많거나 복잡할수록 **과적합(overfitting)** 위험이 커짐  
- 따라서 **검증(Validation) / 교차검증(Cross-validation)** 등을 통해  
  가장 적절한 모델 복잡도(적합한 변수 조합)를 찾아야 함  

> 💡 핵심:  
> 훈련 데이터 성능이 좋다고 해서 모델이 잘 학습된 것은 아님.  
> → 반드시 검증 데이터로 **모델의 일반화 능력**을 확인해야 함.


## 4-2. 다중선형회귀 시 회귀계수 해석의 주의점

### 🎯 회귀분석으로 답할 수 있는 질문
- 변수들 간의 관계를 설명하거나, 독립변수가 종속변수에 미치는 영향을 추정하는 것

### ⚠️ 주의해야 할 상황
1. **이상적 상황**
   - 변수들이 서로 독립적일 때 → 회귀계수 해석이 명확
2. **문제 상황**
   - 변수 간 상관관계가 존재할 경우  
     → 계수 추정이 불안정해지고, 해석이 혼동될 수 있음  
     → 이를 **다중공선성(Multicollinearity)** 문제라고 함  


### 🚫 상관관계와 인과관계 구분
- 회귀분석 결과에서 **상관관계(correlation)** 가 높다고 해서  
  반드시 **인과관계(causation)** 가 있는 것은 아님  
- 관찰 데이터만으로 인과성을 단정짓는 것은 위험함  

#### 📌 예시
- 광고 데이터의 경우: 광고비와 매출 간 인과성이 있어 보이지만,  
  실제로는 제3의 요인(경쟁사, 계절, 경기 상황 등)이 영향을 줄 수 있음  
- “아이스크림 소비량(X)”과 “상어에 물리는 사건(Y)”  
  → 둘 다 여름철에 증가하므로 상관관계는 있으나 인과관계는 아님  


> 💬 **핵심 요약**
> - 선형회귀 모델의 성능은 **훈련·테스트 분리 평가**로 검증해야 함  
> - 다중회귀에서 변수 간 상관성이 높으면 계수 해석이 불안정해짐  
> - 회귀계수의 해석 시 **상관관계 ≠ 인과관계** 임을 항상 인지해야 함  
> - 모델의 신뢰도를 높이기 위해선 **EDA → 검증 → 해석 → 주의점 점검** 순으로 접근해야 함

---
## 🧭 선형회귀 요약 및 정리

### 📘 선형회귀 개요
- 지도학습(Supervised Learning)의 가장 기초적인 방법  
- 입력(X)과 출력(Y) 간의 **선형 관계**를 학습하여 예측  
- 목표: 데이터를 가장 잘 설명하는 직선을 찾아 예측에 활용  


## 🔹 단순선형회귀 (Simple Linear Regression)

### 📗 모형
Y = β₀ + β₁X + ε  

| 기호 | 의미 |
|------|------|
| β₀ | 절편 (X=0일 때의 Y 값) |
| β₁ | 기울기 (X가 1 증가할 때 Y의 평균 증가량) |
| ε | 오차항 (실제값과 예측값의 차이, 잔차) |

- **학습 방법:** 최소제곱법(Least Squares) → 잔차제곱합(RSS)을 최소화  
- **예시:** TV 광고비(X)와 매출(Y)의 관계  

### 💡 핵심 개념
- **잔차(Residual):** 실제값과 예측값의 차이 (eᵢ = yᵢ - ŷᵢ)  
- **RSS (Residual Sum of Squares):** Σ(eᵢ²) → 작을수록 모델이 데이터를 잘 설명  
- **최소제곱법:** RSS를 최소화하는 β₀, β₁을 찾는 원리  


## 🔹 다중선형회귀 (Multiple Linear Regression)

### 📗 모형
Y = β₀ + β₁X₁ + β₂X₂ + … + βₚXₚ + ε  

- 여러 독립변수를 동시에 고려하여 종속변수를 예측  
- 예시: TV, Radio, Newspaper 광고비 → 매출 예측  

### 📈 해석
- 다른 변수를 고정한 상태에서 Xⱼ가 1 증가하면 Y는 평균적으로 βⱼ만큼 변화  
- 계수 β는 각 변수의 **영향력 크기와 방향**을 의미  

### ⚙️ 계수 추정
- RSS 최소화를 통해 β 추정  
- 정규방정식 해: β̂ = (XᵀX)⁻¹Xᵀy  
- 결과는 평면(Hyperplane) 형태로 표현  


## ⚠️ 선형회귀 주의사항

### 1️⃣ 검증 / 테스트 데이터 분리
- 학습 데이터만으로 평가하면 과적합(Overfitting) 위험  
- 새로운 데이터(Test set)로 **모델의 일반화 성능**을 검증해야 함  

### 2️⃣ 다중공선성(Multicollinearity)
- 변수 간 상관관계가 높을 경우 계수 해석이 불안정해짐  
  - 계수 해석 어려움  
  - 분산 증가 → 추정값이 불안정해짐  

### 3️⃣ 상관관계 ≠ 인과관계
- 두 변수의 상관성이 높다고 해서 반드시 인과관계가 있는 것은 아님  
- 예: 아이스크림 소비량(X) ↔ 상어 사고(Y) → 단순한 계절 요인의 결과  



## 🧾 핵심 정리표

| 구분 | 주요 개념 | 핵심 내용 |
|------|-------------|-------------|
| **목적** | 입력과 출력 간 선형 관계 학습 및 예측 |
| **단순회귀식** | Y = β₀ + β₁X + ε |
| **계수의 의미** | β₀: 절편 / β₁: 기울기 |
| **잔차(Residual)** | 실제값 - 예측값, 모델 적합도 판단 기준 |
| **최소제곱법(Least Squares)** | 잔차제곱합(RSS)을 최소화하는 계수 추정 원리 |
| **다중선형회귀** | 여러 독립변수를 함께 고려해 예측 정확도 향상 |
| **계수 추정식** | β̂ = (XᵀX)⁻¹Xᵀy |
| **주의점** | 과적합, 다중공선성, 상관관계와 인과관계 혼동 주의 |



> 💬 **최종 요약**
> - 선형회귀는 가장 기본적인 예측 모델로, “입력→출력 관계를 직선으로 근사”  
> - 단순회귀는 한 변수, 다중회귀는 여러 변수의 영향을 함께 고려  
> - 핵심은 **잔차 최소화(Least Squares)** 와 **모델의 일반화(Validation)**  
> - 해석 시 다중공선성과 상관·인과 혼동에 유의해야 함
