# CNN

## CNN vs FCN

###  1. FCN (Fully Connected Network)

(1) 개념
- 입력을 **1차원 벡터로 변환(Flatten)** 후 모든 노드가 서로 연결된 구조의 신경망  
- 입력의 모든 특성이 출력 노드에 **동일하게 영향을 미침**  
- 이미지의 공간 구조(픽셀 간 위치 관계)는 고려하지 않음  

(2) 구조 및 동작
- 예시: 32×32×3 이미지를 1×3072 벡터로 변환  
- 가중치 W(10×3072)와 곱해 10개의 출력 생성  
- 각 입력값이 모든 출력에 연결되어 있으므로 **매우 많은 파라미터**가 필요함  

(3) 특징
- 이미지의 **위치 정보 손실** → 형태나 패턴 인식에 비효율적  
- **파라미터 수 과다**, **연산량 많음**, **과적합 위험** 존재  


### 2. CNN (Convolutional Neural Network)

#### 개념
- 이미지의 **2D/3D(이미지의 공간적 구조) 구조를 유지한 채** 특징(feature)을 추출하는 딥러닝 모델
  - FCN은 입력을 1차원으로 펼쳐 모든 노드가 연결되므로, 이미지의 위치정보가 손실됨.
- **합성곱(Convolution)** 연산으로 엣지, 색상 변화, 질감 등을 감지함

#### CNN 핵심 구성요소

**(1) Convolution Layer**
- **필터(커널)** 을 이미지 위에서 슬라이딩하며 내적 연산 수행.  
- 각 필터는 특정 패턴(엣지, 방향, 질감 등)을 감지하도록 학습됨.  
- 여러 필터를 사용하면 다양한 **Feature Map** 을 생성할 수 있음.  
- CNN에서는 이 필터의 값을 **학습 가능한 가중치(Weight)** 로 다룸.

💡 *예: 커널을 슬라이딩하며 곱셈-합산(convolution) → 이미지의 테두리, 패턴, 형태 강조*

**(2) 활성화 함수 (ReLU)**
- Convolution 결과에 **비선형성(non-linearity)** 을 부여해 더 복잡한 관계 학습 가능.  
- ReLU(x) = max(0, x)  
  → 음수는 0으로, 양수는 그대로 유지.  
  → 계산 간단 + 학습 속도 빠름.

💡 *ReLU는 특징을 더욱 두드러지게 만들어 학습 효율 향상*


**(3) Pooling Layer (Max Pooling)**
- **특징맵의 크기를 줄이는 Downsampling 과정**으로, 연산 효율을 높이고 위치 변화에 강건성 확보.  
- 일반적으로 2×2 영역에서 **가장 큰 값(max)** 을 선택.  
- 파라미터 학습 없음 (비학습 연산).

| 입력 영역 | 출력 값 | 설명 |
|------------|----------|------|
| [1, 2, 5, 6] | 6 | 영역 내 최대값 선택 |
| [3, 2, 1, 4] | 4 | 동일 방식 적용 |

💡 *강한 특징만 남기고 노이즈 제거*


**(4) Fully Connected Layer (FC)**
- Convolution과 Pooling으로 얻은 특징맵을 **1차원으로 펼쳐(Flatten)** 분류기로 전달.  
- CNN이 학습한 특징을 이용해 최종적으로 클래스를 예측.  

#### 주요 연산 원리
- 한 필터는 입력 이미지의 작은 영역을 대상으로 가중합(`wᵀx + b`)을 계산  
- **필터 깊이(Channel)** 는 입력과 동일해야 함 (예: 입력 깊이 3 → 필터 깊이도 3)
- 필터를 이동시키면서 모든 영역을 계산 → **활성화 맵(Activation Map)** 생성  
- 출력 크기 = 입력 해상도 - 필터 크기 + 1  
  - 예시: 32 - 5 + 1 = 28 → (32×32 → 28×28)

#### CNN의 장점
- **공간적 구조 보존:** 인접 픽셀 간 관계를 유지하면서 학습  
- **파라미터 수 감소:** 필터를 공유하여 효율적 학습 가능  
- **특징 자동 학습:** 필터가 경계선, 질감, 형태 등 시각적 패턴을 자동으로 학습  


### 3. FCN vs CNN 비교 요약

| 구분 | FCN (Fully Connected) | CNN (Convolutional) |
|------|------------------------|----------------------|
| 입력 형태 | 1차원 벡터로 변환 (Flatten) | 2D/3D 구조 유지 |
| 학습 단위 | 전체 입력 픽셀 | 국소 영역(필터 단위) |
| 특징 추출 | 직접 불가능 | 자동 추출 (Convolution) |
| 파라미터 수 | 매우 많음 | 상대적으로 적음 |
| 공간 정보 | 손실됨 | 보존됨 |
| 대표 활용 | 기본 MLP 구조, 일반 분류 | 이미지·영상 인식, 시각 패턴 학습 |


### 4. 핵심 정리
- **FCN:** 모든 입력이 모든 출력에 연결 → 공간 정보 손실, 비효율적  
- **CNN:** 합성곱을 통해 특징을 자동 추출하고, 공간 구조를 유지하며 학습  
- **출력 계산 예시:**  
  - 입력 32×32, 필터 5×5 → 출력 28×28  
  - 필터가 많을수록 다양한 특징을 학습함  
- CNN은 **딥러닝 기반 시각 인식의 핵심 모델**로, 2012년 **AlexNet** 이후 급격히 발전함

## CNN 모델 구조

### 1. CNN 모델 구조의 기본 개념
- CNN은 입력 이미지에서 **공간적(local) 특징을 추출**하고,  
  여러 합성곱층(Convolution Layer)을 **중첩(stacking)** 하여 **깊은 표현(Deep Representation)** 을 학습함.
- 각 합성곱층은 입력으로부터 더 복잡한 특징을 학습하며,  
  하위층은 단순한 패턴(엣지, 색상 등)을, 상위층은 복합적인 형태(윤곽, 물체 등)를 학습함.


### 2. 합성곱층 구조 (Convolution Layer)

(1) 계층의 확장
- 합성곱층을 여러 번 쌓아 깊은 구조로 확장 가능.  
- 각 층은 서로 다른 **필터 크기 및 개수**를 사용함.
- 예시:
  - 입력: `N × 3 × 32 × 32`
  - 1번째 레이어: `W₁ = 6×3×5×5`, `b₁ = 6` → 출력: `N × 6 × 28 × 28`
  - 2번째 레이어: `W₂ = 10×6×3×3`, `b₂ = 10` → 출력: `N × 10 × 26 × 26`
  - 3번째 레이어: `W₃ = 12×10×3×3`, `b₃ = 12` → 출력: `N × 12 × 24 × 24`

(2) 모델의 비선형성
- 단순히 선형 합성곱만 반복하면 **Linear Classifier**와 동일해짐.  
- 따라서 **비선형 활성화 함수(ReLU)** 를 추가하여 모델의 표현력을 향상시킴.
- 구성 예시:  
  **Conv → ReLU → Conv → ReLU → Conv → ReLU**

### 3. 필터의 의미

(1) 필터 시각화
- 각 필터는 입력 이미지의 특정 패턴을 학습함.
- 학습된 필터는 **각 층마다 다른 특징을 감지**:
  - FCN: 다양한 템플릿(모양, 색상, 질감)을 학습.
  - CNN: 계층별로 이미지의 **국소 패턴(엣지, 색상 변화, 윤곽 등)** 을 학습.

(2) 층별 특징
| 층 깊이 | 학습 특징 | 예시 |
|----------|------------|------|
| 1~2층 | 기본적인 선, 엣지, 색상 | 윤곽선, 방향성 |
| 3~5층 | 질감, 패턴, 구조 | 모양의 일부 |
| 6층 이상 | 복잡한 개체 형태 | 얼굴, 사물 등 |


### 4. 수용영역 (Receptive Field)

(1) 개념
- CNN이 이미지를 처리하면서 **한 번에 볼 수 있는 입력 영역의 크기**.  
- 깊은 층으로 갈수록 수용영역이 넓어져 **전체 맥락(Context)** 을 이해할 수 있음.
- 즉, 하위층은 “지역 정보”를, 상위층은 “전체 구조”를 인식함.

(2) 특징
- 깊은 네트워크일수록 수용영역이 확장됨 → **넓은 맥락 파악 가능**
- 고해상도 이미지를 처리할 때는 많은 레이어를 통과해야 함.
- 계산 비용과 메모리 부담을 줄이기 위해 입력 크기를 줄여 사용.


### 5. 풀링(Pooling)

(1) 개념
- CNN 출력의 크기를 줄여 **연산 효율 향상** 및 **위치 변화에 대한 강건성 확보**.
- **공간적 축소(Downsampling)** 과정을 수행하며, 중요한 정보만 남김.

(2) 효과
- 연산량 감소: 예를 들어,  
  224×224 → 112×112로 줄이면 약 **4배 효율 향상 (1.85 → 0.46 GFLOPS)**
- **위치 변화 강건성:**  
  입력 내 물체의 위치가 약간 달라져도 출력이 크게 변하지 않음.
- 저해상도 정보 기반으로 학습하여 **불필요한 세부 정보 무시 가능.**

(3) 맥스 풀링(Max Pooling)
- 입력을 일정 크기(예: 2×2)로 분할하고, 각 영역 내 **가장 큰 값(max)** 을 선택.  
- 모델 파라미터는 학습되지 않음 (비학습 연산).  

| 입력 영역 | 출력 값 | 설명 |
|------------|----------|------|
| [1, 2, 5, 6] | 6 | 각 영역 내 최대값 선택 |
| [3, 2, 1, 4] | 4 | 동일 방식 적용 |


### 6. 정리

| 구분 | 역할 | 특징 |
|------|------|------|
| 합성곱층 (Conv) | 이미지의 지역 특징 추출 | 필터와 내적 연산 수행 |
| ReLU | 비선형성 부여 | 모델 표현력 강화 |
| 풀링층 (Pooling) | 크기 축소 및 위치 강건성 확보 | 연산 효율 증가 |
| 수용영역 | 한 번에 보는 입력 영역 | 깊을수록 넓은 맥락 이해 |

### 핵심 요약
- CNN은 **합성곱층 + ReLU + 풀링층** 의 반복으로 구성됨.  
- 깊은 CNN일수록 지역적 특징 → 전역적 의미로 확장 학습.  
- **수용영역** 개념을 통해 지역적 특징과 전체 맥락을 동시에 이해.  
- **풀링 연산**은 효율적 학습과 일반화 성능 향상에 필수적인 과정임.
