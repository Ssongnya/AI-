# MLP (Multi-Layer Perceptron, 다층 퍼셉트론)

### 1. 정의
- MLP는 **하나 이상의 은닉층(Hidden Layer)** 을 가진 **인공신경망(ANN)** 의 한 형태이다.  
- 입력층(Input) → 은닉층(Hidden) → 출력층(Output)으로 구성된다.  
- 각 노드(뉴런)는 이전 층의 모든 노드와 연결된 **완전연결층(Fully Connected Layer)** 형태를 가진다.  
- 활성화 함수를 통해 **비선형성(Non-Linearity)** 을 부여함으로써 복잡한 관계를 학습할 수 있다.


### 2. 구조와 동작 원리
- 각 층의 노드는 입력값에 **가중치(weight)** 와 **편향(bias)** 를 곱하고 더한 뒤,  
  **활성화 함수(Activation Function)** 를 적용하여 출력값을 만든다.  
- 수식 형태:  
  `a = f(w₁x₁ + w₂x₂ + … + wₙxₙ + b)`

**구성요소 정리**
| 구성 요소 | 역할 |
|------------|------|
| 입력층 (Input Layer) | 데이터를 받아들이는 층 |
| 은닉층 (Hidden Layer) | 가중치 연산과 활성화 함수를 통해 특징 추출 |
| 출력층 (Output Layer) | 예측 결과를 산출 (예: 분류 확률, 회귀값 등) |
| 가중치(Weight) | 입력이 출력에 미치는 영향의 크기를 조정 |
| 편향(Bias) | 출력값을 보정하여 더 유연한 모델 생성 |
| 활성화 함수 | 비선형 변환을 통해 복잡한 관계를 학습 가능하게 함 |


### 3. 활성화 함수 (Activation Function)
- **비선형성**을 부여하여 모델이 단순 선형 관계를 넘어서 복잡한 패턴을 학습할 수 있게 만든다.

| 함수 | 특징 |
|------|------|
| Sigmoid | 출력 범위 0~1, 확률 표현에 유용하나 기울기 소실 문제가 있음 |
| Tanh | 출력 범위 -1~1, 중심이 0이어서 학습 안정성이 높음 |
| ReLU | 음수는 0, 양수는 그대로 통과 — 계산 효율이 높고 가장 널리 사용 |
| Leaky ReLU | ReLU의 단점(죽은 뉴런 문제)을 완화한 형태 |

> 활성화 함수가 없다면 MLP는 선형회귀와 같은 단순 모델이 되어 복잡한 패턴을 학습할 수 없다.


### 4. 학습 과정 (Training Process)
1. **순전파(Forward Propagation)**  
   - 입력 데이터가 각 층을 통과하며 예측값이 계산된다.
2. **손실 계산(Loss Calculation)**  
   - 예측값과 실제값의 차이를 손실함수(Loss Function)로 계산한다.
3. **역전파(Backpropagation)**  
   - 손실을 최소화하기 위해 가중치와 편향을 수정하는 과정이다.  
   - 오차를 역으로 전달하면서 미분(기울기)을 계산하고 가중치를 갱신한다.
4. **최적화(Optimization)**  
   - 옵티마이저(Optimizer)를 통해 가중치를 반복적으로 업데이트하며 손실을 최소화한다.


### 5. MLP의 특징
- **입력과 출력 사이의 복잡한 비선형 관계를 학습할 수 있음**  
- **단층 퍼셉트론(Perceptron)** 이 선형 분류만 가능한 반면,  
  **MLP는 비선형 분류와 회귀 문제 해결 가능**
- **은닉층이 많을수록** 더 복잡한 특징을 학습할 수 있지만,  
  과적합(Overfitting)이나 기울기 소실(Vanishing Gradient) 문제가 발생할 수 있음


### 6. 장점과 한계
| 구분 | 내용 |
|------|------|
| 장점 | 단순 구조로 다양한 데이터(이미지, 텍스트 등)에 적용 가능 |
| 한계 | 층이 깊어질수록 계산량과 학습 시간 증가 |
| 극복 방법 | Dropout, 정규화(Normalization), 옵티마이저 선택(Adam, SGD 등) |


### 7. 핵심 요약
- MLP는 입력 → 은닉 → 출력으로 구성된 **다층 신경망**  
- 비선형 활성화 함수를 통해 복잡한 패턴을 학습  
- 학습 과정은 **순전파 → 손실 계산 → 역전파 → 가중치 갱신** 순서로 이루어진다.  
